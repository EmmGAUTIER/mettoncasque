{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "aadb9de204a24f6fab1f664170561ed7",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "# Processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": "db654247dd3246adadfea0c6a26e1e20",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 215,
    "execution_start": 1723559689788,
    "source_hash": "9a7d27d6"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import json\n",
    "\n",
    "rep_base  = \"../\"\n",
    "rep_src   = rep_base + \"data/raw/\"       # Fichiers téléchargés avant traitement\n",
    "rep_inter = rep_base + \"data/inter/\"     # Des fichiers intermédiaires sont utilisés\n",
    "rep_dst   = rep_base + \"data/processed/\" # Fichiers utilisés par la modélisation\n",
    "rep_ref   = rep_base + \"references/\"     # Dictionnaires décrivants les fichiers et les variables\n",
    "\n",
    "# La liste 'actions' sert à stocker la liste des actions réalisées.\n",
    "# Elle est affichée en fin de notebook et sert à la rédaction du rapport\n",
    "# La fonction log_action affiche et stocke dans actions[].\n",
    "actions  = []\n",
    "def log_action(str):\n",
    "    print (f\" - {str}\")\n",
    "    actions.append(str)\n",
    "\n",
    "# Il y a des variables à écarter, nous enregistrons la liste dans var_ecartees\n",
    "# Nous enregistrons pour chaque var. écartée son nom et la raison.\n",
    "var_ecartees = []\n",
    "    \n",
    "# Lecture de la liste des fichiers, cette liste comprend : les noms\n",
    "# des fichiers, les séparateurs, la période (\"phase\"), les conversions\n",
    "# de type à réaliser et quelques autre infos.\n",
    "with open(rep_ref + \"./desc_fic_raw.json\", 'r', encoding='utf-8') as fichier:\n",
    "    des_fic_raw = json.load(fichier)\n",
    "\n",
    "# Lecture de la description des variables avec leurs libellés\n",
    "# et les correspondances des modalités pour des affichages explicites\n",
    "with open(rep_ref + \"./desc_vars.json\", 'r', encoding='utf-8') as fichier:\n",
    "    desc_vars = json.load(fichier)\n",
    "\n",
    "dfrub = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "7f63113bf2b94775ae57b75a7bd8193e",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "# Lecture des données\n",
    "\n",
    "Les données sont réparties dans 4 rubriques et dans 4 années de 2019 à 2022\n",
    "\n",
    "Les informations sur les fichiers contenues dans le fichier desc_fic_raw.json\n",
    "contiennent :\n",
    "  - Le nom du fichier ;\n",
    "  - Le séparateur ;\n",
    "  - les conversions de types dans dtypes à réaliser lors du chargement ;\n",
    " Le code de la cellule suivante réalise :\n",
    "  - la lecture des fichiers ;\n",
    "  - des conversions de type et le remplacement des \" -1\" par \"-1\"\n",
    "  - le renommage d'une colonne d'un fichier ;\n",
    "  - la concaténation des fichiers de chaque rubrique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": "c72789f2254848bbba6210339f676c9c",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 26467,
    "execution_start": 1723559690028,
    "source_hash": "9e33ca72"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rubrique :  caracteristiques\n",
      "caracteristiques-2019.csv (58840, 15)\n",
      "caracteristiques-2020.csv (47744, 15)\n",
      "carcteristiques-2021.csv (56518, 15)\n",
      "  - rename  {'Accident_Id': 'Num_Acc'}\n",
      "carcteristiques-2022.csv (55302, 15)\n",
      "caract-2023.csv (54822, 15)\n",
      "Nombre de DataFrames  :  5\n",
      "Nombre d'observations :  273226 273226\n",
      "Colonnes du DataFrame :  15\n",
      "\n",
      "Rubrique :  usagers\n",
      "usagers-2019.csv (132977, 15)\n",
      "usagers-2020.csv (105295, 15)\n",
      "usagers-2021.csv (129248, 16)\n",
      "usagers-2022.csv (126662, 16)\n",
      "usagers-2023.csv (125789, 16)\n",
      "Nombre de DataFrames  :  5\n",
      "Nombre d'observations :  619971 619971\n",
      "Colonnes du DataFrame :  16\n",
      "\n",
      "Rubrique :  vehicules\n",
      "vehicules-2019.csv (100710, 11)\n",
      "vehicules-2020.csv (81066, 11)\n",
      "vehicules-2021.csv (97315, 11)\n",
      "vehicules-2022.csv (94493, 11)\n",
      "vehicules-2023.csv (93585, 11)\n",
      "Nombre de DataFrames  :  5\n",
      "Nombre d'observations :  467169 467169\n",
      "Colonnes du DataFrame :  11\n",
      "\n",
      "Rubrique :  lieux\n",
      "lieux-2019.csv (58840, 18)\n",
      "lieux-2020.csv (47744, 18)\n",
      "lieux-2021.csv (56518, 18)\n",
      "lieux-2022.csv (55302, 18)\n",
      "lieux-2023.csv (70860, 18)\n",
      "Nombre de DataFrames  :  5\n",
      "Nombre d'observations :  289264 289264\n",
      "Colonnes du DataFrame :  18\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for rubrique, description_rub in des_fic_raw.items():  # Pour chaque rubrique\n",
    "    nb_obs = 0  # nombre total d'observation (lignes, hors entêtes)\n",
    "\n",
    "    print ()\n",
    "    print(\"Rubrique : \", rubrique)\n",
    "    \n",
    "    dfl = []  # Liste de dataframes lus dans le fichiers.\n",
    "    dtype = description_rub.get(\"dtypes\")\n",
    "    \n",
    "\n",
    "    for fichier_origine in description_rub[\"fichiers\"]:  # Pour chaque fichier annuel\n",
    "        nom_fichier = fichier_origine[\"nom\"]\n",
    "        # lecture du fichier\n",
    "        df = pd.read_csv(rep_src + nom_fichier,\n",
    "                         sep=fichier_origine[\"sep\"],\n",
    "                         dtype=dtype,\n",
    "                         encoding=\"latin_1\",\n",
    "                         index_col=False,\n",
    "                         quotechar=\"\\\"\",\n",
    "                         low_memory=False)\n",
    "        nb_obs += df.shape[0]\n",
    "        if fichier_origine.get(\"rename_cols\") is not None:\n",
    "            df = df.rename(columns=fichier_origine.get(\"rename_cols\"))\n",
    "            print(\"  - rename \", fichier_origine.get(\"rename_cols\"))\n",
    "        print(nom_fichier, df.shape)  # Pour info et mise au point\n",
    "        dfl.append(df)\n",
    "\n",
    "     # Concaténation de tous les DataFrames annuels (2019->2023)\n",
    "    dfrub[rubrique] = pd.concat(dfl)\n",
    "    \n",
    "    # Remplacement des \" -1\" par \"-1\"\n",
    "    # Les valeurs manquantes sont codées \"-1\" et parfois \" -1\", avec une espace en plus\n",
    "    # Il faut alors supprimer cette espace qui n'a pas de sens.\n",
    "    dfrub[rubrique] = dfrub[rubrique].replace(\" -1\", \"-1\")\n",
    "\n",
    "    print(\"Nombre de DataFrames  : \", len(dfl))\n",
    "    print(\"Nombre d'observations : \", nb_obs, dfrub[rubrique].shape[0])\n",
    "    print(\"Colonnes du DataFrame : \", dfrub[rubrique].shape[1])\n",
    "\n",
    "    #dfrub[rubrique].to_csv(rep_dst + rubrique + \".csv\", sep='\\t', index=False)\n",
    "\n",
    "dfu = dfrub[\"usagers\"]\n",
    "dfv = dfrub[\"vehicules\"]\n",
    "dfl = dfrub[\"lieux\"]\n",
    "dfc = dfrub[\"caracteristiques\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "c60e3baf6c084ba6861958137a6cdec6",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "# Jointure des 4 rubriques\n",
    "\n",
    "Les jointures sont toutes faites avec le champ Num_Acc\n",
    "Le type de Num_Acc est forcé à int lors de la lecture par read_csv()\n",
    "La dernière jointure avec les véhicules est faite avec, en plus,\n",
    "les champs num_veh et id_vehicule.\n",
    "Les jointures sont \"à gauche\" (\"left\")\n",
    "pour conserver le nombre d'usagers.\n",
    "Les nombres d'observations et de variables affichés avant et après\n",
    "chaque jointure permettent de vérifier les jointures.\n",
    "Il y a 494 182 usagers avant les jointures et le DataFrame résultant\n",
    "a ce même nombre d'observations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": "51df6f77d16c4e6db86dd97956bd2561",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 4980,
    "execution_start": 1723559734134,
    "source_hash": "bec57eb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " - Jointure usagers  <---  caracteristiques\n",
      "\n",
      "Taille usagers          :  (619971, 16)\n",
      "Taille caractéristiques :  (273226, 15)\n",
      "Tailles df résultant    :  (619971, 30)\n",
      "\n",
      " - Jointure (usagers et caracteristiques)  <---  lieux\n",
      "\n",
      "Taille DataFrame        :  (619971, 30)\n",
      "Taille lieux            :  (289264, 18)\n",
      "Tailles df résultant    :  (657865, 47)\n",
      "\n",
      " - Jointure (usagers, caracteristiques et lieux)  <---  vehicules\n",
      "\n",
      "Taille DataFrame        :  (657865, 47)\n",
      "Taille vehicules        :  (467169, 11)\n",
      "Tailles df résultant    :  (657865, 55)\n",
      "\n",
      "Colonnes résultantes :  Index(['Num_Acc', 'id_vehicule', 'num_veh', 'place', 'catu', 'grav', 'sexe',\n",
      "       'an_nais', 'trajet', 'secu1', 'secu2', 'secu3', 'locp', 'actp', 'etatp',\n",
      "       'id_usager', 'jour', 'mois', 'an', 'hrmn', 'lum', 'dep', 'com', 'agg',\n",
      "       'int', 'atm', 'col', 'adr', 'lat', 'long', 'catr', 'voie', 'v1', 'v2',\n",
      "       'circ', 'nbv', 'vosp', 'prof', 'pr', 'pr1', 'plan', 'lartpc', 'larrout',\n",
      "       'surf', 'infra', 'situ', 'vma', 'senc', 'catv', 'obs', 'obsm', 'choc',\n",
      "       'manv', 'motor', 'occutc'],\n",
      "      dtype='object')\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 657865 entries, 0 to 657864\n",
      "Data columns (total 55 columns):\n",
      " #   Column       Non-Null Count   Dtype  \n",
      "---  ------       --------------   -----  \n",
      " 0   Num_Acc      657865 non-null  int64  \n",
      " 1   id_vehicule  657865 non-null  object \n",
      " 2   num_veh      657865 non-null  object \n",
      " 3   place        657865 non-null  object \n",
      " 4   catu         657865 non-null  object \n",
      " 5   grav         657865 non-null  object \n",
      " 6   sexe         657865 non-null  object \n",
      " 7   an_nais      648412 non-null  object \n",
      " 8   trajet       657865 non-null  object \n",
      " 9   secu1        657865 non-null  object \n",
      " 10  secu2        657865 non-null  object \n",
      " 11  secu3        657865 non-null  object \n",
      " 12  locp         657865 non-null  object \n",
      " 13  actp         657865 non-null  object \n",
      " 14  etatp        657865 non-null  object \n",
      " 15  id_usager    419593 non-null  object \n",
      " 16  jour         657865 non-null  int64  \n",
      " 17  mois         657865 non-null  int64  \n",
      " 18  an           657865 non-null  int64  \n",
      " 19  hrmn         657865 non-null  object \n",
      " 20  lum          657865 non-null  object \n",
      " 21  dep          657865 non-null  object \n",
      " 22  com          657865 non-null  object \n",
      " 23  agg          657865 non-null  int64  \n",
      " 24  int          657865 non-null  object \n",
      " 25  atm          657865 non-null  object \n",
      " 26  col          657865 non-null  object \n",
      " 27  adr          647763 non-null  object \n",
      " 28  lat          657865 non-null  object \n",
      " 29  long         657865 non-null  object \n",
      " 30  catr         657865 non-null  object \n",
      " 31  voie         581905 non-null  object \n",
      " 32  v1           633269 non-null  object \n",
      " 33  v2           53165 non-null   object \n",
      " 34  circ         657865 non-null  object \n",
      " 35  nbv          657865 non-null  object \n",
      " 36  vosp         657865 non-null  object \n",
      " 37  prof         657865 non-null  object \n",
      " 38  pr           657865 non-null  object \n",
      " 39  pr1          657865 non-null  object \n",
      " 40  plan         657865 non-null  object \n",
      " 41  lartpc       1160 non-null    object \n",
      " 42  larrout      525719 non-null  object \n",
      " 43  surf         657865 non-null  object \n",
      " 44  infra        657865 non-null  object \n",
      " 45  situ         657865 non-null  object \n",
      " 46  vma          657865 non-null  float64\n",
      " 47  senc         657865 non-null  object \n",
      " 48  catv         657865 non-null  int64  \n",
      " 49  obs          657865 non-null  object \n",
      " 50  obsm         657865 non-null  object \n",
      " 51  choc         657865 non-null  object \n",
      " 52  manv         657865 non-null  object \n",
      " 53  motor        657865 non-null  object \n",
      " 54  occutc       8938 non-null    object \n",
      "dtypes: float64(1), int64(6), object(48)\n",
      "memory usage: 276.1+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "########################################################################\n",
    "# Jointures des 4 rubriques \n",
    "########################################################################\n",
    "\n",
    "print(\"\")\n",
    "log_action(\"Jointure usagers  <---  caracteristiques\")\n",
    "#print(\"Un pour un\")\n",
    "print ()\n",
    "print(\"Taille usagers          : \", dfu.shape)\n",
    "print(\"Taille caractéristiques : \", dfc.shape)\n",
    "df = pd.merge(dfu, dfc, on=\"Num_Acc\", how = \"left\")\n",
    "print(\"Tailles df résultant    : \", df.shape)\n",
    "\n",
    "print(\"\")\n",
    "log_action(\"Jointure (usagers et caracteristiques)  <---  lieux\")\n",
    "print()\n",
    "print(\"Taille DataFrame        : \", df.shape)\n",
    "print(\"Taille lieux            : \", dfl.shape)\n",
    "df = pd.merge(df, dfl, on=\"Num_Acc\", how = \"left\")\n",
    "print(\"Tailles df résultant    : \", df.shape)\n",
    "\n",
    "print(\"\")\n",
    "log_action(\"Jointure (usagers, caracteristiques et lieux)  <---  vehicules\")\n",
    "print()\n",
    "print(\"Taille DataFrame        : \", df.shape)\n",
    "print(\"Taille vehicules        : \", dfv.shape)\n",
    "df = pd.merge(df, dfv, on=[\"Num_Acc\", \"id_vehicule\", \"num_veh\"], how = \"left\")\n",
    "\n",
    "print(\"Tailles df résultant    : \", df.shape)\n",
    "print ()\n",
    "print (\"Colonnes résultantes : \", df.columns)\n",
    "\n",
    "print (df.info(max_cols=1000, show_counts=True))\n",
    "# Libérons de la mémoire.\n",
    "# Les DataFrames des 4 rubriques ne seront plus utilisés\n",
    "dfc = None\n",
    "dfl = None\n",
    "dfu = None\n",
    "dfv = None\n",
    "dfrub = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "ee85a6fd76e240ea86eaa1bf81fa1a8f",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "# Suppression d'observations\n",
    "Nous supprimons les observations dont la gravité est inconnue,\n",
    "la gravité inconnue est codée -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_id": "da66374e32714b3b9dfab763b429b89e",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 514,
    "execution_start": 1723559739131,
    "source_hash": "9f7ae458"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre d'observations avant suppression 657865\n",
      "Nombre d'observations supprimées        0\n",
      "Nombre d'observations après suppression 657865\n",
      " - Suppression de 0 observations dont la gravité est inconnue (codée -1)\n"
     ]
    }
   ],
   "source": [
    "nb_avant = df.shape[0]\n",
    "print (f\"Nombre d'observations avant suppression {nb_avant}\")\n",
    "df1 = df.loc[df.grav!='-1',:]\n",
    "print (f\"Nombre d'observations supprimées        {nb_avant- df.shape[0]}\")\n",
    "print (f\"Nombre d'observations après suppression {df.shape[0]}\")\n",
    "log_action(f\"Suppression de {nb_avant- df.shape[0]} observations dont la gravité est inconnue (codée -1)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "5789f69b8324407dbe5246fcbc52e6b2",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "# Création de variables\n",
    "\n",
    "## Création de la variable indiquant un jour ferié\n",
    "\n",
    "Cette variable nous permettra de déterminer si les jours feriés\n",
    "expliquent la gravité des accidents. Les jours fériés sont les dimanches\n",
    "et les jours de fête.\n",
    "\n",
    "## Création de la variable du jour de la semaine\n",
    "\n",
    "Cette variable nous permettra de déterminer si le jour de la\n",
    "semaine explique la gravité des accidents.\n",
    "\n",
    "## Création de la variable indiquant l'âge\n",
    "\n",
    "Le jeu de données contient l'année de naissance des usagers et l'année\n",
    "de l'accident. Nous créons la variable age égal à la différence\n",
    "entre l'année de l'accident et l'année de naissance.\n",
    "Lorsque l'année de naissance est inconnue l'âge est codé -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cell_id": "25f0a5b4185a4f0d8bfffe7850397446",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 2497,
    "execution_start": 1723559739705,
    "source_hash": "cc2b582f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - Inclusion du jour de la semaine dans le fichier\n",
      "Jours de la semaine : \n",
      "jsem\n",
      "1     87857\n",
      "2     93880\n",
      "3     94548\n",
      "4     94159\n",
      "5    107885\n",
      "6     96837\n",
      "7     82699\n",
      "Name: count, dtype: int64\n",
      " - Création de la variable jsem : jour de la semaine\n",
      "Jours ouvrés et fériés\n",
      "ferie\n",
      "False    566069\n",
      "True      91796\n",
      "Name: count, dtype: int64\n",
      " - Création de la variable ferie : jour férié, dimanches et autres fêtes\n",
      "9453\n",
      " - Création de la variable age : différence entre l'année de l'accident et l'année de naissance\n"
     ]
    }
   ],
   "source": [
    "# Creation de colonnes :\n",
    "#   - ferie : 0 jour ouvré, 1 : jour ferié\n",
    "#   - jsem : jour de la semaine : lundi : 1 , ... , 7 : dimanche\n",
    "\n",
    "##############################################################################\n",
    "# Inclusion du jour de la semaine\n",
    "##############################################################################\n",
    "\n",
    "print(\"  - Inclusion du jour de la semaine dans le fichier\")\n",
    "df_date = df[[\"an\", \"mois\", \"jour\"]]\n",
    "df_date = df_date.rename({\"an\": \"year\", \"mois\": \"month\", \"jour\": \"day\"}, axis=1)\n",
    "df_date[\"ts\"] = pd.to_datetime(df_date)\n",
    "# weekday() return :  Monday is 0 and Sunday is 6.\n",
    "# La modalité zéro signifiant parfois non renseigné ou non applicable\n",
    "# nous préférons ajouter 1 à la valeur retournée par weekday()\n",
    "df_date[\"jsem\"] = df_date.ts.apply(lambda x: x.weekday()+1)\n",
    "\n",
    "df[\"jsem\"] = df_date.jsem\n",
    "df_date = None  # Libérons un peu de mémoire\n",
    "\n",
    "print (\"Jours de la semaine : \")\n",
    "print (df.jsem.value_counts().sort_index())\n",
    "log_action (f\"Création de la variable jsem : jour de la semaine\")\n",
    "\n",
    "##############################################################################\n",
    "# Création de la variable ferie\n",
    "# elle vaut 1 si le jour est ferie, 0 sinon\n",
    "# Les jours fériés sont les dimanches et les jours de fête.\n",
    "##############################################################################\n",
    "\n",
    "df[\"ferie\"] = False\n",
    "\n",
    "# Les dimanches\n",
    "df.loc[df.jsem==7,\"ferie\"] = True\n",
    "\n",
    "# Les 1er janvier\n",
    "df.loc[(df.mois == '1') & (df.jour == '1'), 'ferie'] = True\n",
    "\n",
    "# Les 1er mai\n",
    "df.loc[(df[\"mois\"]==5) & (df[\"jour\"]==1), \"ferie\"] = True\n",
    "\n",
    "# Les 8 mai\n",
    "df.loc[(df.mois==5) & (df.jour==8), \"ferie\"] = True\n",
    "\n",
    "# Les 14 juillet\n",
    "df.loc[(df.mois==7) & (df.jour==14), \"ferie\"] = True\n",
    "\n",
    "# Les 15 août\n",
    "df.loc[(df.mois==7) & (df.jour==14), \"ferie\"] = True\n",
    "\n",
    "# Les 1er novembre\n",
    "df.loc[(df.mois==11) & (df.jour==1), \"ferie\"] = True\n",
    "\n",
    "# Les 11 novembre\n",
    "df.loc[(df.mois==11) & (df.jour==11), \"ferie\"] = True\n",
    "\n",
    "# Les 25 décembre\n",
    "df.loc[(df.mois==12) & (df.jour==25), \"ferie\"] = True\n",
    "\n",
    "# Dimanche de pâques, date variant chaque année\n",
    "df.loc[(df.an == 2019) & (df.mois==4) & (df.jour==21), \"ferie\"] = True\n",
    "df.loc[(df.an == 2020) & (df.mois==4) & (df.jour==12), \"ferie\"] = True\n",
    "df.loc[(df.an == 2021) & (df.mois==4) & (df.jour==4),  \"ferie\"] = True\n",
    "df.loc[(df.an == 2022) & (df.mois==4) & (df.jour==17), \"ferie\"] = True\n",
    "\n",
    "# Lundi de pentecôte, date variant chaque année\n",
    "df.loc[(df.an == 2019) & (df.mois==6) & (df.jour==10), \"ferie\"] = True\n",
    "df.loc[(df.an == 2020) & (df.mois==6) & (df.jour==1), \"ferie\"] = True\n",
    "df.loc[(df.an == 2021) & (df.mois==5) & (df.jour==24),  \"ferie\"] = True\n",
    "df.loc[(df.an == 2022) & (df.mois==6) & (df.jour==6), \"ferie\"] = True\n",
    "\n",
    "# Jeudi de l'ascension, date variant chaque année\n",
    "df.loc[(df.an == 2019) & (df.mois==5) & (df.jour==30), \"ferie\"] = True\n",
    "df.loc[(df.an == 2020) & (df.mois==5) & (df.jour==21), \"ferie\"] = True\n",
    "df.loc[(df.an == 2021) & (df.mois==5) & (df.jour==13),  \"ferie\"] = True\n",
    "df.loc[(df.an == 2022) & (df.mois==5) & (df.jour==26), \"ferie\"] = True\n",
    "\n",
    "# Saint Étienne en alsace Moselle, le 26 décembre\n",
    "df.loc[ df.dep.isin([57, 67, 68]) & (df.mois==12) & (df.jour==26), \"ferie\"] = True\n",
    "\n",
    "# Abolition de l'esclavage en Guadeloupe\n",
    "df.loc[(df.dep == 971) & (df.mois==5) & (df.jour==27), \"ferie\"] = True\n",
    "\n",
    "# Abolition de l'esclavage en Martinique\n",
    "df.loc[(df.dep == 972) & (df.mois==5) & (df.jour==22), \"ferie\"] = True\n",
    "\n",
    "# Abolition de l'esclavage en Guyane\n",
    "df.loc[(df.dep == 973) & (df.mois==6) & (df.jour==10), \"ferie\"] = True\n",
    "\n",
    "# Abolition de l'esclavage à la Réunion\n",
    "df.loc[(df.dep == 974) & (df.mois==12) & (df.jour==20), \"ferie\"] = True\n",
    "\n",
    "# Abolition de l'esclavage à Mayotte\n",
    "df.loc[(df.dep == 976) & (df.mois==4) & (df.jour==27), \"ferie\"] = True\n",
    "\n",
    "# Abolition de l'esclavage à Saint-Barthélémy\n",
    "df.loc[(df.dep == 977) & (df.mois==10) & (df.jour==9), \"ferie\"] = True\n",
    "\n",
    "# Abolition de l'esclavage à Saint-Martin\n",
    "df.loc[(df.dep == 978) & (df.mois==5) & (df.jour==28), \"ferie\"] = True\n",
    "\n",
    "print (\"Jours ouvrés et fériés\")\n",
    "print (df.ferie.value_counts())\n",
    "log_action (f\"Création de la variable ferie : jour férié, dimanches et autres fêtes\")\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "# Création de la variable age\n",
    "# Elle est égale à l'année de l'accident moins l'année de naissance à un an près.\n",
    "# L'année de naissance n'est pas toujours connue, elle est alors codée -1\n",
    "# TODO : gérer l'arrondi\n",
    "##############################################################################\n",
    "\n",
    "print (df.an_nais.isna().sum())\n",
    "\n",
    "# Lorsque la date de naissance est inconnue,\n",
    "# l'âge est codé avec une valeur négative.\n",
    "ag = df.an.astype(\"int\") - df.an_nais.fillna(2030).astype (\"int\")\n",
    "ag.loc[ag<0] = -1\n",
    "df[\"age\"] = ag\n",
    "ag = None  # Libération de la mémoire\n",
    "\n",
    "log_action (f\"Création de la variable age : différence entre l'année de l'accident et l'année de naissance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Écart des véhicules pour lesquels le casque n'est pas obligatoire\n",
    "Notre étude porte vise à montrer l'importance du port du casque lors d'un accident."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre d'observations : 156043\n",
      "Nombre d'observations : 156043\n",
      "Répartition par catégorie de véhicule :\n",
      "catv\n",
      "33    44330\n",
      "1     30118\n",
      "2     21566\n",
      "30    17939\n",
      "32    13171\n",
      "31    10054\n",
      "50     9907\n",
      "34     6436\n",
      "36     1182\n",
      "60     1175\n",
      "35      165\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Répartition par gravité :\n",
      "grav\n",
      "4     93066\n",
      "3     43545\n",
      "1     14037\n",
      "2      5339\n",
      "-1       56\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f\"Nombre d'observations : {df.shape[0]}\")\n",
    "df = df[df[\"catv\"].isin([1, 2, 30, 31, 32, 33, 34, 35, 36, 50, 60])]\n",
    "print(f\"Nombre d'observations : {df.shape[0]}\")\n",
    "print (\"Répartition par catégorie de véhicule :\")\n",
    "print (df[\"catv\"].value_counts())\n",
    "print ()\n",
    "print (\"Répartition par gravité :\")\n",
    "print (df[\"grav\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "706eb4d27ff14a319c00301016c71beb",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "# Dichotomisation  / catégorisation\n",
    "La plupart des variables du jeu de données sont qualitatives et\n",
    "le modèle entraîné doit faire de la catégorisation.\n",
    "Nous procédons alors à la dichotomisation des variables catégorielles.\n",
    "Nous avons constaté la présence de valeurs non renseignées dans le jeu de données,\n",
    "elles sont parfois absentes et le plus souvent codées \"-1\" ou \" -1\".\n",
    "Nous avons aussi constaté dans certaines variables la modalité \"non applicable\",\n",
    "c'est par exemple le cas de la place de l'usager dans le véhicule lorsqu'il est piéton.\n",
    "Nous utilisons une fonction \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "9d4d7f7754054a6cb078ba47867dbcfb",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 62,
    "execution_start": 1723559742222,
    "source_hash": "11fba077"
   },
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "# Fonction de dichotomisation adaptée\n",
    "##############################################################################\n",
    "\n",
    "def dichotomisation (df, column, var_ecartees, desc_vars=None, dummies=None, mod_ecartees = None):\n",
    "    \"\"\"\n",
    "    Cette fonction fait la dichotomisation des seules modalités de la\n",
    "    liste fournie par dummies. Elle permet de ne pas dichotomiser les\n",
    "    modalités : \"non renseigné\", \"Autre\", \"Non applicable\", ...\n",
    "    Elle utilise si possible les infos de desc_vars pour nommer les colonnes.\n",
    "    et elle complète desc_vars.\n",
    "    \"\"\"\n",
    "    try :\n",
    "        desc_vars = desc_vars.get(\"columns\")\n",
    "        col_desc = {}\n",
    "        for c in desc_vars :\n",
    "            if c.get(\"name\") == column:\n",
    "                col_desc = c\n",
    "                break\n",
    "    except :\n",
    "        col_desc = {}\n",
    "\n",
    "    if dummies is None:\n",
    "        dum = list(df[column].unique())\n",
    "    else:\n",
    "        dum = dummies\n",
    "    if mod_ecartees is not None:\n",
    "        dum = [x for x in dum if x not in mod_ecartees]\n",
    "    print()\n",
    "    \n",
    "    # Pour chaque variable correspondant à une modalité\n",
    "    for c in dum: # c : modalité\n",
    "        \n",
    "        # Le nom de la nvle variable est le nom de la var. et la modalité\n",
    "        new_col_name = column + \"_\" + str(c)\n",
    "        \n",
    "        # Création de la nouvelle variable (colonne)\n",
    "        df[new_col_name] = df[column] == c\n",
    "        \n",
    "        # Recherche d'une description existante dans la liste des descriptions\n",
    "        # les descriptions sont dans un tableau qu'il faut adresser avec un entier\n",
    "        desc_new_col = None\n",
    "        for ic in range(len(desc_vars)):\n",
    "            if desc_vars[ic].get(\"name\") == new_col_name:\n",
    "                desc_new_col = desc_vars[ic]\n",
    "                break\n",
    "            \n",
    "        if desc_new_col is None:\n",
    "            desc_new_col = {}\n",
    "            desc_new_col[\"name\"] = new_col_name\n",
    "            desc_new_col[\"dtype\"] = \"bool\"\n",
    "            values = col_desc.get(\"values\")\n",
    "            if values is not None and values.get(c) is not None:\n",
    "                desc_new_col[\"label\"] = col_desc.get(\"label\") + \" : \" + values.get(c)\n",
    "            else :\n",
    "                desc_new_col[\"label\"] = col_desc.get(\"label\")\n",
    "            desc_vars.append(desc_new_col)\n",
    "\n",
    "    var_ecartees.append ((column, \"Dichotomisation\"))\n",
    "    # df = df.copy()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "bc5e4e39c87742258ad59021870bc312",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 15307,
    "execution_start": 1723559742295,
    "source_hash": "b5a72086"
   },
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "# Dichotomisation des champs secu 1 à 3\n",
    "##############################################################################\n",
    "# L'usager peut être protégé par plusieurs équipements, il y a trois variables\n",
    "# pour décrire ces équipements, il y a 6 types d'équipement, il faut alors\n",
    "# créer six modalités. \n",
    "\n",
    "df[\"secu_ceinture\"]   = False\n",
    "df[\"secu_casque\"]     = False\n",
    "df[\"secu_dispenfant\"] = False\n",
    "df[\"secu_gilet\"]      = False\n",
    "df[\"secu_airbag23RM\"] = False\n",
    "df[\"secu_gants\"]      = False\n",
    "\n",
    "df.loc[df.secu1 == '1', \"secu_ceinture\"] = True\n",
    "df.loc[df.secu2 == '1', \"secu_ceinture\"] = True\n",
    "df.loc[df.secu3 == '1', \"secu_ceinture\"] = True\n",
    "\n",
    "df.loc[df.secu1 == '2', \"secu_casque\"] = True\n",
    "df.loc[df.secu2 == '2', \"secu_casque\"] = True\n",
    "df.loc[df.secu3 == '2', \"secu_casque\"] = True\n",
    "\n",
    "df.loc[df.secu1 == '3', \"secu_dispenfant\"] = True\n",
    "df.loc[df.secu2 == '3', \"secu_dispenfant\"] = True\n",
    "df.loc[df.secu3 == '3', \"secu_dispenfant\"] = True\n",
    "\n",
    "df.loc[df.secu1 == '4', \"secu_gilet\"] = True\n",
    "df.loc[df.secu2 == '4', \"secu_gilet\"] = True\n",
    "df.loc[df.secu3 == '4', \"secu_gilet\"] = True\n",
    "\n",
    "df.loc[df.secu1 == '5', \"secu_airbag23RM\"] = True\n",
    "df.loc[df.secu2 == '5', \"secu_airbag23RM\"] = True\n",
    "df.loc[df.secu3 == '5', \"secu_airbag23RM\"] = True\n",
    "df.loc[df.secu1 == '7', \"secu_airbag23RM\"] = True\n",
    "df.loc[df.secu2 == '7', \"secu_airbag23RM\"] = True\n",
    "df.loc[df.secu3 == '7', \"secu_airbag23RM\"] = True\n",
    "\n",
    "df.loc[df.secu1 == '6', \"secu_gants\"] = True\n",
    "df.loc[df.secu2 == '6', \"secu_gants\"] = True\n",
    "df.loc[df.secu3 == '6', \"secu_gants\"] = True\n",
    "df.loc[df.secu1 == '7', \"secu_gants\"] = True\n",
    "df.loc[df.secu2 == '7', \"secu_gants\"] = True\n",
    "df.loc[df.secu3 == '7', \"secu_gants\"] = True\n",
    "\n",
    "var_ecartees.append((\"secu1\", \"Dichotomisation\"))\n",
    "var_ecartees.append((\"secu2\", \"Dichotomisation\"))\n",
    "var_ecartees.append((\"secu3\", \"Dichotomisation\"))\n",
    "#df = df.drop([\"secu1\", \"secu2\", \"secu3\"], axis = 1)\n",
    "log_action(f\"Dichotomisation des champs secu1, secu2 et secu3\")\n",
    "\n",
    "##############################################################################\n",
    "# Dichotomisation de l'âge\n",
    "# TODO : À affiner\n",
    "##############################################################################\n",
    "df[\"age_enfant\"]  = (df.age>=0) & (df.age<= 15)\n",
    "df[\"age_jeune\"]   = (df.age>15) & (df.age<= 25)\n",
    "df[\"age_adulte\"]  = (df.age>25) & (df.age<= 64)\n",
    "df[\"age_3age\"]    = (df.age>64)\n",
    "\n",
    "var_ecartees.append((\"age\", \"Dichotomisation\"))\n",
    "log_action(f\"Dichotomisation de l'âge\")\n",
    "\n",
    "##############################################################################\n",
    "# Dichotomisation de l'heure\n",
    "##############################################################################\n",
    "# TODO : faire un équilibrage\n",
    "df[\"hr_matin\"] = (df.hrmn>=\"0600\") & (df.hrmn<\"1200\") \n",
    "df[\"hr_midi\"]  = (df.hrmn>=\"1200\") & (df.hrmn<\"1400\") \n",
    "df[\"hr_am\"]    = (df.hrmn>=\"1400\") & (df.hrmn<\"1800\") \n",
    "df[\"hr_soir\"]  = (df.hrmn>=\"1800\") & (df.hrmn<\"2100\") \n",
    "df[\"hr_nuit\"]  = (df.hrmn>=\"2100\") | (df.hrmn<\"0600\") \n",
    "\n",
    "var_ecartees.append((\"hrmn\", \"Dichotomisation\"))\n",
    "log_action(f\"Dichotomisation de l'heure\")\n",
    "\n",
    "##############################################################################\n",
    "# Dichotomisation du sexe\n",
    "##############################################################################\n",
    "df[\"sexe_m\"] = df.sexe == '1'\n",
    "df[\"sexe_f\"] = df.sexe == '2'\n",
    "\n",
    "var_ecartees.append((\"sexe\", \"Dichotomisation\"))\n",
    "log_action(f\"Dichotomisation du sexe\")\n",
    "\n",
    "##############################################################################\n",
    "# Dichotomisation de la gravité\n",
    "##############################################################################\n",
    "# Les noms de variables seront plus faciles à retenir que les valeurs 1 à 4\n",
    "# N.B.: les observations dont la gravité est inconnue (codée -1) seront écartées\n",
    "df[\"grav_grave\"]       = df.grav.isin([\"2\", \"3\"])\n",
    "\n",
    "var_ecartees.append((\"grav\", \"Dichotomisation\"))\n",
    "log_action(f\"Dichotomisation de la gravité\")\n",
    "\n",
    "##############################################################################\n",
    "# Dichotomisation du nombre de voies de circulation avec regroupement\n",
    "##############################################################################\n",
    "df[\"nbv_1\"]    = df.nbv == '1'\n",
    "df[\"nbv_2\"]    = df.nbv == '2'\n",
    "df[\"nbv_3\"]    = df.nbv == '3'\n",
    "df[\"nbv_4\"]    = df.nbv == '4'\n",
    "df[\"nbv_plus\"] = df.nbv.isin(['5', '6', '7', '8', '9', '10','11', '12'])\n",
    "\n",
    "var_ecartees.append((\"nbv\", \"Dichotomisation\"))\n",
    "log_action(f\"Dichotomisation du nombre de voies avec regroupement 1 à 4 puis 5 et plus\")\n",
    "\n",
    "##############################################################################\n",
    "# Dichotomisation de l'état de la surface\n",
    "##############################################################################\n",
    "df[\"surf_norm\"]  = df.surf == '1'\n",
    "df[\"surf_mouil\"] = df.surf == '2'\n",
    "df[\"surf_gliss\"] = df.surf.isin(['3', '4', '5', '6', '7', '8', '9'])\n",
    "df[\"surf_autre\"] = df.surf == '9'\n",
    "\n",
    "var_ecartees.append((\"surf\", \"Dichotomisation\"))\n",
    "log_action(f\"Dichotomisation du l'état de la surface : sèche, mouillée, glissante (3 à 9)\")\n",
    "\n",
    "##############################################################################\n",
    "# Dichotomisation de la vitesse maximale autorisée\n",
    "##############################################################################\n",
    "# la vma (vitesse maximale autorisée) est codée par un flottant\n",
    "# Il y a des valeurs abberrantes et codées avec des points décimaux\n",
    "# Nous les convertissons en entiers\n",
    "vma_int = df.vma.astype(int)\n",
    "df[\"vma_30m\"] = vma_int.isin([10, 20, 30])\n",
    "df[\"vma_40\"]  = vma_int == 40\n",
    "df[\"vma_50\"]  = vma_int == 50\n",
    "df[\"vma_60\"]  = vma_int == 60\n",
    "df[\"vma_70\"]  = vma_int == 70\n",
    "df[\"vma_80\"]  = vma_int == 80\n",
    "df[\"vma_90\"]  = vma_int == 90\n",
    "df[\"vma_110\"] = vma_int == 110\n",
    "df[\"vma_130\"] = vma_int == 130\n",
    "\n",
    "var_ecartees.append((\"vma\", \"Dichotomisation\"))\n",
    "log_action(f\"Dichotomisation de la vitesse maximale autorisée avec regroupement\")\n",
    "\n",
    "##############################################################################\n",
    "# agg : En ou hors agglomération\n",
    "##############################################################################\n",
    "# modalités 1 et 2, sans valueurs nulles (-1 ou na)\n",
    "df.agg_agg = df.agg == '1'\n",
    "var_ecartees.append((\"agg\", \"Dichotomisation\"))\n",
    "log_action(\"Dichotomisation en ou hors agglomération (agg), 1 agglomération, 0 hors agglomoration\")\n",
    "\n",
    "##############################################################################\n",
    "# Dichotomisations plus simples\n",
    "##############################################################################\n",
    "\n",
    "# actp : action du piéton\n",
    "dummies = ['1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B']\n",
    "dichotomisation(df, \"actp\", var_ecartees, desc_vars, dummies = dummies)\n",
    "log_action(\"Dichotomisation de l'action du piéton (actp), modalité -1 0 et B exclues\")\n",
    "\n",
    "# atm : Conditions atmosphériques\n",
    "dummies = ['1', '2', '3', '4', '5', '6', '7', '8']\n",
    "dichotomisation(df, \"atm\", var_ecartees, desc_vars, dummies = dummies)\n",
    "log_action(\"Dichotomisation des cond. atmosphériques (atm), modalité -1 et 9 exclues\")\n",
    "\n",
    "# catr : Catégorie de route\n",
    "dummies = ['1', '2', '3', '4', '5', '6', '7']\n",
    "dichotomisation(df, \"catr\", var_ecartees, desc_vars, dummies = dummies)\n",
    "log_action(\"Dichotomisation de la catégorie de route (catr)), modalité -1 et 9 exclues\")\n",
    "\n",
    "# catu : Catégorie d'usager\n",
    "dummies = ['1', '2', '3']\n",
    "dichotomisation(df, \"catu\", var_ecartees, desc_vars, dummies = dummies)\n",
    "log_action(\"Dichotomisation de la catégorie d'usager (catu), modalité -1 exclue\")\n",
    "\n",
    "# catv : Catégorie de véhicule\n",
    "dichotomisation(df, \"catv\", var_ecartees, desc_vars, dummies = None, mod_ecartees=[0, -1])\n",
    "log_action(\"Dichotomisation de la catégorie de véhicule (catv), modalité -1 et 0 exclues\")\n",
    "\n",
    "# choc : Point de choc initial\n",
    "dichotomisation(df, \"choc\", var_ecartees, desc_vars, dummies = None, mod_ecartees=['0', '-1'])\n",
    "log_action(\"Dichotomisation du point de choc initial (choc), modalité -1 et 0 exclues\")\n",
    "\n",
    "# circ : Circulation\n",
    "dichotomisation(df, \"circ\", var_ecartees, desc_vars, dummies = None, mod_ecartees=['-1'])\n",
    "log_action(\"Dichotomisation du régime de circulation (circ), modalité -1 exclue\")\n",
    "\n",
    "# col : Type de collision\n",
    "dichotomisation(df, \"col\", var_ecartees, desc_vars, dummies = None, mod_ecartees=['-1'])\n",
    "log_action(\"Dichotomisation du type de collision (col), modalité -1 exclue\")\n",
    "\n",
    "# etatp: Piéton seul\n",
    "dichotomisation(df, \"etatp\", var_ecartees, desc_vars, dummies = ['1', '2', '3'])\n",
    "log_action(\"Dichotomisation de (etatp), modalité -1 exclue\")\n",
    "\n",
    "# infra : Aménagement - infrastructure\n",
    "dichotomisation(df, \"infra\", var_ecartees, desc_vars, dummies = None, mod_ecartees=['-1', '0'])\n",
    "log_action(\"Dichotomisation de Aménagement - infrastructure (infra), modalités -1 et 0 exclues\")\n",
    "\n",
    "# int : type d'intersection\n",
    "dichotomisation(df, \"int\", var_ecartees, desc_vars, dummies = None, mod_ecartees=['-1'])\n",
    "log_action(\"Dichotomisation du type d'intersection (int), modalité -1  exclues\")\n",
    "\n",
    "# jsem : Jour de la semaine\n",
    "dichotomisation(df, \"jsem\", var_ecartees, desc_vars, dummies = None, mod_ecartees=None)\n",
    "log_action(\"Dichotomisation du jour de la semaine (jsem), toutes modalité \")\n",
    "\n",
    "# locp : Localisation du piéton\n",
    "dichotomisation(df, \"locp\", var_ecartees, desc_vars, dummies = None, mod_ecartees = ['-1', '0'])\n",
    "log_action(\"Dichotomisation de la localisation du piéton (locp), modalités -1, 0(non renseigné) exclues\")\n",
    "\n",
    "# lum : Lumière modalité\n",
    "dichotomisation(df, \"lum\", var_ecartees, desc_vars, dummies = None, mod_ecartees = ['-1'])\n",
    "log_action(\"Dichotomisation des conditions lumineuses (lum), modalité -1 exclue\")\n",
    "\n",
    "# manv : Manœuvre\n",
    "dichotomisation(df, \"manv\", var_ecartees, desc_vars, dummies = None, mod_ecartees = ['-1', '0'])\n",
    "log_action(\"Dichotomisation de la manœuvre (manv), modalité -1 et 0 exclues\")\n",
    "\n",
    "# mois : Mois\n",
    "dichotomisation(df, \"mois\", var_ecartees, desc_vars, dummies = None, mod_ecartees = None)\n",
    "log_action(\"Dichotomisation du mois (mois), toutes modalités\")\n",
    "\n",
    "# motor : Motorisation\n",
    "dichotomisation(df, \"motor\", var_ecartees, desc_vars, dummies = None, mod_ecartees = ['-1', '0'])\n",
    "log_action(\"Dichotomisation de la motorisation (motor), modalité -1 et 0 exclues\")\n",
    "\n",
    "# obs : Obstacle fixe heurté\n",
    "dichotomisation(df, \"obs\", var_ecartees, desc_vars, dummies = None, mod_ecartees = ['-1', '0'])\n",
    "log_action(\"Dichotomisation de l'obstacle fixe heurté (obs), modalité -1 et 0 exclues\")\n",
    "\n",
    "# obsm : Obstacle mobile heurté\n",
    "dichotomisation(df, \"obsm\", var_ecartees, desc_vars, dummies = None, mod_ecartees = ['-1', '0'])\n",
    "log_action(\"Dichotomisation de l'obstacle mobile heurté (obsm), modalité -1 et 0 exclues\")\n",
    "\n",
    "# place : Place de l'usager dans le véhicule\n",
    "dichotomisation(df, \"place\", var_ecartees, desc_vars, dummies = None, mod_ecartees = ['-1'])\n",
    "log_action(\"Dichotomisation de la place dans le véhicule (place), modalité -1 exclue\")\n",
    "\n",
    "# plan : Tracé en plan\n",
    "dichotomisation(df, \"plan\", var_ecartees, desc_vars, dummies = None, mod_ecartees = ['-1'])\n",
    "log_action(\"Dichotomisation du tracé en plan (plan), modalité -1 exclue\")\n",
    "\n",
    "# prof : Déclivité\n",
    "dichotomisation(df, \"prof\", var_ecartees, desc_vars, dummies = None, mod_ecartees = ['-1'])\n",
    "log_action(\"Dichotomisation de la déclivité (prof), modalité -1 exclue\")\n",
    "\n",
    "# senc : sens de circulation\n",
    "dichotomisation(df, \"senc\", var_ecartees, desc_vars, dummies = None, mod_ecartees = ['-1'])\n",
    "log_action(\"Dichotomisation du sens de circulation (senc), modalité -1, 0 et 3 exclues\")\n",
    "\n",
    "# situ : Situation de l'accident\n",
    "dichotomisation(df, \"situ\", var_ecartees, desc_vars, dummies = None, mod_ecartees = ['-1'])\n",
    "log_action(\"Dichotomisation de la situation de l'accident (situ), modalité -1 exclue\")\n",
    "\n",
    "# trajet : Motif du trajet\n",
    "dichotomisation(df, \"trajet\", var_ecartees, desc_vars, dummies = None, mod_ecartees = ['-1'])\n",
    "log_action(\"Dichotomisation du motif du trajet (trajet), modalité -1 exclue\")\n",
    "\n",
    "# vosp : Présence d'une voie réservée\n",
    "dichotomisation(df, \"vosp\", var_ecartees, desc_vars, dummies = None, mod_ecartees = ['-1'])\n",
    "log_action(\"Dichotomisation de la présence d'une voie réservée (vosp), modalités -1 exclue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "408ed721e63149409d0229ebcce8959e",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 471,
    "execution_start": 1723559757611,
    "source_hash": "72854dcc"
   },
   "outputs": [],
   "source": [
    "print (\"Matin      : \", df.hr_matin.sum())\n",
    "print (\"Midi       : \", df.hr_midi.sum())\n",
    "print (\"après-midi : \", df.hr_am.sum())\n",
    "print (\"soir       : \", df.hr_soir.sum())\n",
    "print (\"Nuit       : \", df.hr_nuit.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "2a10f430b1ba45b7862594bd5413b128",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 422,
    "execution_start": 1723559757660,
    "source_hash": "6e716eec"
   },
   "outputs": [],
   "source": [
    "print (\"Enfants  : \", df.age_enfant.sum())\n",
    "print (\"jeunes   : \", df.age_jeune.sum())\n",
    "print (\"adultes  : \", df.age_adulte.sum())\n",
    "print (\"3ème âge : \", df.age_3age.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "42a8af6530aa496a93b3b2c98855b16d",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "# Suppression de variables\n",
    "Nous supprimons des variables pour les raisons suivantes :\n",
    "  - Codage douteux, valeurs trop dispersées ;\n",
    "  - Remplacées par d'autres variables (calculées) ;\n",
    "  - variables dichotomisées ;\n",
    "  - Index servant aux jointures et n'expliquant rien."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "372e4167def44f8ca87e45c81b98632c",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1197,
    "execution_start": 1723559757708,
    "source_hash": "c1a4017"
   },
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "# Ajout à la liste des variables trop dispersées ou douteuses pour suppression\n",
    "##############################################################################\n",
    "var_ecartees.append((\"adr\",     \"Dispersion trop importante\"))\n",
    "var_ecartees.append((\"com\",     \"Dispersion trop importante\"))\n",
    "var_ecartees.append((\"dep\",     \"Dispersion trop importante\"))\n",
    "var_ecartees.append((\"larrout\", \"Valeurs douteuses\"))\n",
    "var_ecartees.append((\"lartpc\",  \"Valeurs douteuses\"))\n",
    "var_ecartees.append((\"lat\",     \"Valeurs douteuses\"))\n",
    "var_ecartees.append((\"long\",    \"Valeurs douteuses\"))\n",
    "var_ecartees.append((\"occutc\",  \"trop de nuls\"))\n",
    "var_ecartees.append((\"pr\",      \"Dispersion\"))\n",
    "var_ecartees.append((\"pr1\",     \"Dispersion\"))\n",
    "var_ecartees.append((\"v1\",      \"Dispersion\"))\n",
    "var_ecartees.append((\"v2\",      \"Dispersion\"))\n",
    "var_ecartees.append((\"voie\",    \"Dispersion\"))\n",
    "\n",
    "##############################################################################\n",
    "# Ajout à la liste des variables remplacées (calculées) pour suppression\n",
    "##############################################################################\n",
    "var_ecartees.append((\"an\",      \"Utilisée pour déterminer les jours fériés et l'âge puis supprimée\"))\n",
    "var_ecartees.append((\"an_nais\", \"Utilisée avec 'an' pour calculer l'âge puis supprimée\"))\n",
    "var_ecartees.append((\"jour\",    \"Utilisée pour déterminer si le jour est férié puis suppimée\"))\n",
    "\n",
    "##############################################################################\n",
    "# Ajout à la liste des variables dichotomisées pour suppression\n",
    "##############################################################################\n",
    "# Les noms des variables ont déjà été ajoutées à var_ecartees\n",
    "# par la fonction dichotomisation.\n",
    "\n",
    "##############################################################################\n",
    "# Ajout à la liste des variables d'index pour suppression\n",
    "##############################################################################\n",
    "\n",
    "var_ecartees.append((\"Num_Acc\",      \"Variable d'index\"))\n",
    "var_ecartees.append((\"id_usager\",    \"Variable d'index\"))\n",
    "var_ecartees.append((\"id_vehicule\",  \"Variable d'index\"))\n",
    "var_ecartees.append((\"num_veh\",      \"Variable d'index\"))\n",
    "\n",
    "variables_a_supprimer = [ve[0] for ve in var_ecartees]\n",
    "\n",
    "# Lors de la mise au point de ce notebook la liste des variables à écarter\n",
    "# est complétée avec des valeurs déjà présentes, drop est alors perturbée\n",
    "# et ne supprime pas les variables. Il faut supprimer les doublons.\n",
    "# C'est fait en convertissant la liste en ensmblme (set)\n",
    "# puis en la recovertissant en liste.\n",
    "variables_a_supprimer = set(variables_a_supprimer)\n",
    "variables_a_supprimer = list(variables_a_supprimer)\n",
    "\n",
    "print (\"Variables à supprimer : \", variables_a_supprimer)\n",
    "df = df.drop (columns = variables_a_supprimer, axis = 1)\n",
    "\n",
    "print(f\"Il reste les {df.shape[1]} colonnes suivantes :\", end=\" \")\n",
    "print(\"[\" + \", \".join(f\"'{col}'\" for col in df.columns) + \"]\")\n",
    "\n",
    "print (\"Valeurs nulles :\\n\", df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "aa24ebe18f804297aa8132a5aed1559b",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 141,
    "execution_start": 1723559758918,
    "source_hash": "fe094c23"
   },
   "source": [
    "# Suppression de doublons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "87c6fa35a07f4d8ba0e09082454bba1a",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 3912,
    "execution_start": 1723559758919,
    "source_hash": "9f654320"
   },
   "outputs": [],
   "source": [
    "avant_supp = df.shape[0]\n",
    "df = df.drop_duplicates()\n",
    "apres_supp = df.shape[0]\n",
    "print (\"Suppression d'observations :\")\n",
    "print (f\"  avant suppression {avant_supp:7d}\")\n",
    "print (f\"  nous supprimons   {avant_supp - apres_supp:7d}\")\n",
    "print (f\"  après suppression {apres_supp:7d}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "228086f1109a4484acb85d97cf9c55af",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "# Équilibrage ou réduction de dimension\n",
    "La répartition des modalités de la variable cible est très déséquilibrée\n",
    "Notre objectif est de prédire les conditions des accidents ayant ayant entraîné une hospitalisation de plus de 24h ou la mort.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "222c1ab6430a4d6fbd58af95a922cb41",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1695,
    "execution_start": 1723559762890,
    "source_hash": "274ce376"
   },
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "# Équilibrage des modalités de la variable cible\n",
    "##############################################################################\n",
    "\n",
    "print (\"Répartition avant réduction :\")\n",
    "print (df.value_counts(\"grav_grave\"))\n",
    "print (f\"total : {df.shape[0]:6d}\")\n",
    "X = df.drop(\"grav_grave\", axis = 1)\n",
    "y = df.grav_grave\n",
    "rus = RandomUnderSampler(random_state = 8421)\n",
    "X, y = rus.fit_resample(X, y)\n",
    "df = pd.concat([X, y], axis = 1)\n",
    "print (\"Répartition après réduction :\")\n",
    "print(df.value_counts(\"grav_grave\"))\n",
    "print (f\"total :{df.shape[0]:6d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "98250a0a04df490fa9dad6cdc3528a44",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 66,
    "execution_start": 1723559764590,
    "scrolled": true,
    "source_hash": "e81f2b30"
   },
   "outputs": [],
   "source": [
    "df.grav_grave.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "6257836513f6437eb5e9ccd3729b2e1f",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 159,
    "execution_start": 1723559764650,
    "source_hash": "42b943ec"
   },
   "outputs": [],
   "source": [
    "nb_obs = df.shape[0]\n",
    "for col in df.columns:\n",
    "    print(f\"{col:15s}   {df[col].sum():6d}  {100.*df[col].sum()/nb_obs:10.7f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "c909a2d926154c3fa08f13298125c7e7",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 467,
    "execution_start": 1723559764846,
    "source_hash": "2649655a"
   },
   "outputs": [],
   "source": [
    "print (\"Actions réalisées :\")\n",
    "for a in actions:\n",
    "    print (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "# Enregistrements :\n",
    "#   - Le jeu de données préparé pour la modélisation ;\n",
    "#   - La description des variables mise à jour.\n",
    "##############################################################################\n",
    "\n",
    "df.to_csv(rep_dst + '/' + \"data.csv\", sep = '\\t', index=False, encoding='utf-8')\n",
    "\n",
    "with open(\"./desc_vars.json\", 'w', encoding='utf-8') as fichier:\n",
    "    json.dump(desc_vars, fichier, ensure_ascii=True, indent=True)"
   ]
  }
 ],
 "metadata": {
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "2dec51ceb9bf4391b29e81337dba1028",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
